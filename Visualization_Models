#1: Odds Ratios for Predictor Variables

import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
data = pd.read_csv(r"C:\Users\twarr\Downloads\College_Data (1).csv")

# Create a binary target variable for graduation rate > 62.3%
data['target'] = (data['Grad.Rate'] > 62.3).astype(int)

# Selecting predictor variables
predictors = ['PhD', 'S.F.Ratio', 'Expend']

# Add a constant for the intercept in the logistic regression
X = sm.add_constant(data[predictors])
y = data['target']

# Fit the logistic regression model
model = sm.Logit(y, X)
result = model.fit()

# Calculate the odds ratios and their 95% confidence intervals
odds_ratios = pd.DataFrame({
    'Variable': predictors,
    'Odds Ratio': np.exp(result.params[1:]),  # Skip the constant
    'Lower CI': np.exp(result.conf_int().loc[:, 0][1:]),  # Skip the constant
    'Upper CI': np.exp(result.conf_int().loc[:, 1][1:])   # Skip the constant
})

# Display odds ratios
print(odds_ratios)

# Visualization of odds ratios
plt.figure(figsize=(10, 6))
sns.barplot(x='Odds Ratio', y='Variable', data=odds_ratios, orient='h', color='teal')
plt.axvline(x=1, linestyle='--', color='red')  # Reference line for an odds ratio of 1
plt.title('Odds Ratios for Predicting Graduation Rate > 62.3%')
plt.xlabel('Odds Ratio')
plt.ylabel('Predictor Variables')
plt.show()






#2: Predicted Probability Curves
import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler

# Load the dataset
data = pd.read_csv(r"C:\Users\twarr\Downloads\College_Data (1).csv")

# Create a binary target variable for graduation rate > 62.3%
data['target'] = (data['Grad.Rate'] > 62.3).astype(int)

# Selecting predictor variables
predictors = ['PhD', 'S.F.Ratio', 'Expend']
X = data[predictors]
y = data['target']

# Standardize the predictors to avoid overflow
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=predictors)

# Add a constant for the intercept in the logistic regression
X_scaled = sm.add_constant(X_scaled)

# Fit the logistic regression model
model = sm.Logit(y, X_scaled)
result = model.fit()

# Function to generate predicted probabilities for a range of a predictor
def plot_predicted_probability(predictor, X_scaled, result, original_data):
    # Create a range of standardized values for the predictor
    min_val = X_scaled[predictor].min()
    max_val = X_scaled[predictor].max()
    values = np.linspace(min_val, max_val, 100)
    
    # Create a DataFrame to hold constant values and varying predictor
    pred_df = pd.DataFrame({predictor: values})
    
    # Fill other predictors with their median values (in standardized form)
    for var in X_scaled.columns:
        if var != predictor and var != 'const':
            pred_df[var] = X_scaled[var].median()
    
    # Add constant term for prediction
    pred_df['const'] = 1.0
    
    # Generate predicted probabilities
    pred_probs = result.predict(pred_df)
    
    # Plot predicted probabilities
    plt.figure(figsize=(8, 6))
    plt.plot(values, pred_probs, color='teal', linewidth=2)
    plt.title(f'Predicted Probability of Graduation Rate > 62.3% vs {predictor} (Standardized)')
    plt.xlabel(f'{predictor} (Standardized)')
    plt.ylabel('Predicted Probability')
    plt.ylim(0, 1)
    plt.grid(True)
    plt.show()

# Plot predicted probability curves for each predictor
for predictor in predictors:
    plot_predicted_probability(predictor, X_scaled, result, data)






#3: Confusion Matrix Visualization
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
data = pd.read_csv(r"C:\Users\twarr\Downloads\College_Data (1).csv")

# Create a binary target variable for graduation rate > 62.3%
data['target'] = (data['Grad.Rate'] > 62.3).astype(int)

# Selecting predictor variables including categorical 'Private' variable
predictors = [
    'Private', 'Apps', 'Top10perc', 'F.Undergrad', 'P.Undergrad', 
    'Outstate', 'Room.Board', 'Books', 'Personal', 'PhD', 
    'Terminal', 'S.F.Ratio', 'perc.alumni', 'Expend'
]
X = data[predictors]
y = data['target']

# Convert categorical variable 'Private' to numeric (0 for No, 1 for Yes) using .loc
X.loc[:, 'Private'] = X['Private'].apply(lambda x: 1 if x == 'Yes' else 0)

# Standardize the numerical predictors
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=predictors)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Fit the logistic regression model
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Make predictions on the test set
y_pred = log_reg.predict(X_test)

# Generate the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
class_names = ['<= 62.3%', '> 62.3%']  # Class labels for visualization

# Visualization of the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix for Logistic Regression Model')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Display classification report
print(classification_report(y_test, y_pred, target_names=class_names))




# ROC Curve
from sklearn.metrics import roc_curve, roc_auc_score

# Generate predicted probabilities for the test set
y_probs = log_reg.predict_proba(X_test)[:, 1]

# Compute the ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_probs)
auc = roc_auc_score(y_test, y_probs)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.2f})', color='teal', linewidth=2)
plt.plot([0, 1], [0, 1], linestyle='--', color='red')  # Random guess reference
plt.title('ROC Curve for Logistic Regression Model')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()




# Summary Table of Metrics

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Display metrics in a table
summary_table = pd.DataFrame({
    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'],
    'Value': [accuracy, precision, recall, f1, auc]
})
print(summary_table)



# Histogram 

plt.figure(figsize=(8, 6))
sns.histplot(data['Grad.Rate'], bins=20, kde=True, color='skyblue')
plt.axvline(62.3, color='red', linestyle='--', label='Threshold = 62.3%')
plt.title('Distribution of Graduation Rates')
plt.xlabel('Graduation Rate')
plt.ylabel('Frequency')
plt.legend()
plt.show()


# Box Plot

plt.figure(figsize=(6, 4))
sns.boxplot(x=data['Grad.Rate'], color='lightblue')
plt.axvline(62.3, color='red', linestyle='--', label='Threshold = 62.3%')
plt.title('Box Plot of Graduation Rates')
plt.xlabel('Graduation Rate')
plt.legend()
plt.show()


